{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BWkq0E2HHSZC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 Building and Testing Helper Function:\n",
        "1. Implementing Sigmoid Function:\n",
        "\n",
        "  1. Task To Do:\n",
        "  \n",
        "     Implement the Logistic Function by completing the code or writing your own function."
      ],
      "metadata": {
        "id": "zigqvG7UOx_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_function(x):\n",
        "    \"\"\"\n",
        "    Computes the logistic function applied to any value of x.\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "    x: scalar or numpy array of any size.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    y: logistic function applied to x.\n",
        "\n",
        "    \"\"\"\n",
        "    x_arr = np.asarray(x)\n",
        "    y = 1.0 / (1.0 + np.exp(-x_arr))\n",
        "    # return scalar for scalar input, numpy array otherwise\n",
        "    if np.isscalar(x):\n",
        "        return float(y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "jmtBp222OwND"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test for logistic_function"
      ],
      "metadata": {
        "id": "aJ-KZH491bQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logistic_function():\n",
        "    \"\"\"\n",
        "    Test cases for the logistic_function.\n",
        "    \"\"\"\n",
        "    # Test with scalar input\n",
        "    x_scalar = 0\n",
        "    expected_output_scalar = round(1 / (1 + np.exp(0)), 3)  # 0.5\n",
        "    assert round(logistic_function(x_scalar), 3) == expected_output_scalar, \"Test failed for scalar input\"\n",
        "\n",
        "    # Test with positive scalar input\n",
        "    x_pos = 2\n",
        "    expected_output_pos = round(1 / (1 + np.exp(-2)), 3)  # ~0.881\n",
        "    assert round(logistic_function(x_pos), 3) == expected_output_pos, \"Test failed for positive scalar input\"\n",
        "\n",
        "    # Test with negative scalar input\n",
        "    x_neg = -3\n",
        "    expected_output_neg = round(1 / (1 + np.exp(3)), 3)  # ~0.047\n",
        "    assert round(logistic_function(x_neg), 3) == expected_output_neg, \"Test failed for negative scalar input\"\n",
        "\n",
        "    # Test with numpy array input\n",
        "    x_array = np.array([0, 2, -3])\n",
        "    expected_output_array = np.array([0.5, 0.881, 0.047])\n",
        "    assert np.all(np.round(logistic_function(x_array), 3) == expected_output_array), \"Test failed for numpy array input\"\n",
        "\n",
        "    print(\"All tests passed for logistic_function!\")\n",
        "\n",
        "# Run test\n",
        "test_logistic_function()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYIdfOa_2_dO",
        "outputId": "2613276e-1141-46d3-8002-222d532e1dc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed for logistic_function!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Implementing Log Loss Function"
      ],
      "metadata": {
        "id": "Nshk-Bs33JZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Implementing Log Loss Function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def log_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes log loss for true target value y ={0 or 1} and predicted target value y' inbetween {0-1}.\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "    y_true (scalar): true target value {0 or 1}.\n",
        "\n",
        "    y_pred (scalar): predicted taget value {0-1}.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    loss (float): loss/error value\n",
        "\n",
        "    \"\"\"\n",
        "    # Convert to numpy arrays to handle scalar or array inputs uniformly\n",
        "    y_true_arr = np.asarray(y_true)\n",
        "    y_pred_arr = np.asarray(y_pred)\n",
        "\n",
        "    # If any predicted probability is exactly 0 or 1, raise ValueError\n",
        "    if np.any(y_pred_arr <= 0.0) or np.any(y_pred_arr >= 1.0):\n",
        "        raise ValueError(\"y_pred contains 0 or 1 which would cause log(0). Expected probabilities in (0,1).\")\n",
        "\n",
        "    # element-wise binary cross-entropy\n",
        "    loss = - (y_true_arr * np.log(y_pred_arr) + (1 - y_true_arr) * np.log(1 - y_pred_arr))\n",
        "\n",
        "    return loss if loss.shape != () else float(loss)\n",
        "\n",
        "\n",
        "# Quick verification prints\n",
        "print(\"Demo log_loss examples:\")\n",
        "print(\"log_loss(0, 0.1) =>\", log_loss(0, 0.1))\n",
        "print(\"log_loss(1, 0.9) =>\", log_loss(1, 0.9))\n",
        "\n",
        "\n",
        "# Test cases for log_loss (as in worksheet)\n",
        "def test_log_loss():\n",
        "    import numpy as np\n",
        "    # Test 1: perfect prediction y_true=1, y_pred=1 -> should raise ValueError\n",
        "    try:\n",
        "        log_loss(1, 1)\n",
        "        raise AssertionError(\"Expected ValueError for y_pred=1\")\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    # Test 2: perfect prediction y_true=0, y_pred=0 -> should raise ValueError\n",
        "    try:\n",
        "        log_loss(0, 0)\n",
        "        raise AssertionError(\"Expected ValueError for y_pred=0\")\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    # Test 3: partially correct predictions\n",
        "    y_true = 1\n",
        "    y_pred = 0.8\n",
        "    expected_loss = -(1 * np.log(0.8)) - (0 * np.log(1 - 0.8))\n",
        "    assert np.isclose(log_loss(y_true, y_pred), expected_loss, atol=1e-6), \"Test failed for (1,0.8)\"\n",
        "\n",
        "    y_true = 0\n",
        "    y_pred = 0.2\n",
        "    expected_loss = -(0 * np.log(0.2)) - (1 * np.log(1 - 0.2))\n",
        "    assert np.isclose(log_loss(y_true, y_pred), expected_loss, atol=1e-6), \"Test failed for (0,0.2)\"\n",
        "\n",
        "    print(\"All tests passed for log_loss!\")\n",
        "\n",
        "# Run test\n",
        "test_log_loss()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fK5Y-rc3N0N",
        "outputId": "ea6540a8-31e9-4ce2-8387-8bf0262b87a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demo log_loss examples:\n",
            "log_loss(0, 0.1) => 0.10536051565782628\n",
            "log_loss(1, 0.9) => 0.10536051565782628\n",
            "All tests passed for log_loss!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Implementing Cost Function"
      ],
      "metadata": {
        "id": "h8WW05Hp5Lo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Implementing Cost Function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def cost_function(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes log loss for inputs true value (0 or 1) and predicted value (between 0 and 1)\n",
        "\n",
        "    Args:\n",
        "\n",
        "    y_true (array_like, shape (n,)): array of true values (0 or 1)\n",
        "\n",
        "    y_pred (array_like, shape (n,)): array of predicted values (probability of y_pred being 1)\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    cost (float): nonnegative cost corresponding to y_true and y_pred\n",
        "\n",
        "    \"\"\"\n",
        "    assert len(y_true) == len(y_pred), \"Length of true values and length of predicted values do not match\"\n",
        "\n",
        "    n = len(y_true)\n",
        "    loss_vec = log_loss(np.asarray(y_true), np.asarray(y_pred))  # uses log_loss which may raise ValueError if preds are 0/1\n",
        "    cost = np.mean(loss_vec)\n",
        "    return float(cost)\n",
        "\n",
        "\n",
        "# Test for cost_function (as in worksheet)\n",
        "def test_cost_function():\n",
        "    import numpy as np\n",
        "    y_true = np.array([1, 0, 1])\n",
        "    y_pred = np.array([0.9, 0.1, 0.8])\n",
        "    expected_cost = (-(1 * np.log(0.9)) - (0 * np.log(1 - 0.9)) +\n",
        "                     -(0 * np.log(0.1)) - (1 * np.log(1 - 0.1)) +\n",
        "                     -(1 * np.log(0.8)) - (0 * np.log(1 - 0.8))) / 3.0\n",
        "    result = cost_function(y_true, y_pred)\n",
        "    assert np.isclose(result, expected_cost, atol=1e-6), f\"Test failed: {result} != {expected_cost}\"\n",
        "    print(\"Test passed for cost_function!\")\n",
        "\n",
        "# Run test\n",
        "test_cost_function()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2vBimHw5O_w",
        "outputId": "2c4f3231-900f-4efb-a697-e7fd37bc8d73"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed for cost_function!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Cost function for logistic regression parameters (vectorized)"
      ],
      "metadata": {
        "id": "N9gtuMmi5deL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Cost function for logistic regression parameters (vectorized)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def costfunction_logreg(X, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes the cost function, given data and model parameters.\n",
        "\n",
        "    Args:\n",
        "\n",
        "    X (ndarray, shape (m,n)): data on features, m observations with n features.\n",
        "\n",
        "    y (array_like, shape (m,)): array of true values of target (0 or 1).\n",
        "\n",
        "    w (array_like, shape (n,)): weight parameters of the model.\n",
        "\n",
        "    b (float): bias parameter of the model.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    cost (float): nonnegative cost corresponding to y and y_pred.\n",
        "\n",
        "    \"\"\"\n",
        "    n, d = X.shape\n",
        "    assert len(y) == n, \"Number of feature observations and number of target observations do not match.\"\n",
        "    assert len(w) == d, \"Number of features and number of weight parameters do not match.\"\n",
        "\n",
        "    # Matrix-vector multiplication and adding bias\n",
        "    z = X.dot(w) + b\n",
        "\n",
        "    # Compute predictions using logistic function (sigmoid)\n",
        "    y_pred = logistic_function(z)\n",
        "\n",
        "    # Compute the cost using the cost function\n",
        "    cost = cost_function(y, y_pred)\n",
        "    return float(cost)\n",
        "\n",
        "\n",
        "# Test print (as in worksheet example)\n",
        "X_test = np.array([[10, 20], [-10, 10]])\n",
        "y_test = np.array([1, 0])\n",
        "w_test = np.array([0.5, 1.5])\n",
        "b_test = 1\n",
        "print(f\"cost for logistic regression(X = {X_test.tolist()}, y = {y_test.tolist()}, w = {w_test.tolist()}, b = {b_test}) = {costfunction_logreg(X_test, y_test, w_test, b_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oFCSxaW5evd",
        "outputId": "b6cbe236-103d-44fc-96ec-053909b1faf4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost for logistic regression(X = [[10, 20], [-10, 10]], y = [1, 0], w = [0.5, 1.5], b = 1) = 5.500008350784906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1 Compute Gradient"
      ],
      "metadata": {
        "id": "XaVVeihY5lYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_gradient(X, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes gradients of the cost function with respect to model parameters.\n",
        "\n",
        "    Args:\n",
        "\n",
        "    X (ndarray, shape (n,d)): Input data, n observations with d features\n",
        "\n",
        "    y (array_like, shape (n,)): True labels (0 or 1)\n",
        "\n",
        "    w (array_like, shape (d,)): Weight parameters of the model\n",
        "\n",
        "    b (float): Bias parameter of the model\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    grad_w (array_like, shape (d,)): Gradients of the cost function with respect to the weight\n",
        "    parameters\n",
        "\n",
        "    grad_b (float): Gradient of the cost function with respect to the bias parameter\n",
        "\n",
        "    \"\"\"\n",
        "    n, d = X.shape  # X has shape (n, d)\n",
        "    assert len(y) == n, f\"Expected y to have {n} elements, but got {len(y)}\"\n",
        "    assert len(w) == d, f\"Expected w to have {d} elements, but got {len(w)}\"\n",
        "\n",
        "    # Compute z and predictions using logistic function (sigmoid)\n",
        "    z = X.dot(w) + b\n",
        "    y_pred = logistic_function(z)\n",
        "\n",
        "    # Compute gradients\n",
        "    error = (y - y_pred)                       # shape (n,)\n",
        "    grad_w = - (1.0 / n) * X.T.dot(error)     # shape (d,)\n",
        "    grad_b = - (1.0 / n) * np.sum(error)      # scalar\n",
        "\n",
        "    return grad_w, float(grad_b)\n",
        "\n",
        "\n",
        "# Simple assertion test for compute_gradient (as in worksheet)\n",
        "X = np.array([[10, 20], [-10, 10]])\n",
        "y = np.array([1, 0])\n",
        "w = np.array([0.5, 1.5])\n",
        "b = 1\n",
        "grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "print(\"Gradients computed successfully.\")\n",
        "print(f\"grad_w: {grad_w}\")\n",
        "print(f\"grad_b: {grad_b}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBEIWcRg5oLl",
        "outputId": "94731dd8-578f-4928-cdbe-950737276066"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients computed successfully.\n",
            "grad_w: [-4.99991649  4.99991649]\n",
            "grad_b: 0.4999916492890759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2 Implementing Gradient Descent for Training Sigmoid Regression:"
      ],
      "metadata": {
        "id": "NmAnkMUB5uGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def gradient_descent(X, y, w, b, alpha, n_iter, show_cost=False, show_params=True):\n",
        "    \"\"\"\n",
        "    Implements batch gradient descent to optimize logistic regression parameters.\n",
        "\n",
        "    Args:\n",
        "\n",
        "    X (ndarray, shape (n,d)): Data on features, n observations with d features\n",
        "\n",
        "    y (array_like, shape (n,)): True values of target (0 or 1)\n",
        "\n",
        "    w (array_like, shape (d,)): Initial weight parameters\n",
        "\n",
        "    b (float): Initial bias parameter\n",
        "\n",
        "    alpha (float): Learning rate\n",
        "\n",
        "    n_iter (int): Number of iterations\n",
        "\n",
        "    show_cost (bool): If True, displays cost every 100 iterations\n",
        "\n",
        "    show_params (bool): If True, displays parameters every 100 iterations\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    w (array_like, shape (d,)): Optimized weight parameters\n",
        "\n",
        "    b (float): Optimized bias parameter\n",
        "\n",
        "    cost_history (list): List of cost values over iterations\n",
        "\n",
        "    params_history (list): List of parameters (w, b) over iterations\n",
        "\n",
        "    \"\"\"\n",
        "    n, d = X.shape\n",
        "    assert len(y) == n, \"Number of observations in X and y do not match\"\n",
        "    assert len(w) == d, \"Number of features in X and w do not match\"\n",
        "\n",
        "    cost_history = []\n",
        "    params_history = []\n",
        "\n",
        "    for i in range(n_iter):\n",
        "        # Compute gradients\n",
        "        grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "\n",
        "        # Update weights and bias\n",
        "        w -= alpha * grad_w\n",
        "        b -= alpha * grad_b\n",
        "\n",
        "        # Compute cost\n",
        "        cost = costfunction_logreg(X, y, w, b)\n",
        "\n",
        "        # Store cost and parameters\n",
        "        cost_history.append(cost)\n",
        "        params_history.append((w.copy(), b))\n",
        "\n",
        "        # Optionally print cost and parameters\n",
        "        if show_cost and (i % 100 == 0 or i == n_iter - 1):\n",
        "            print(f\"Iteration {i}: Cost = {cost:.6f}\")\n",
        "        if show_params and (i % 100 == 0 or i == n_iter - 1):\n",
        "            print(f\"Iteration {i}: w = {w}, b = {b:.6f}\")\n",
        "\n",
        "    return w, b, cost_history, params_history\n",
        "\n",
        "\n",
        "# Test the gradient_descent function (as in worksheet)\n",
        "X = np.array([[0.1, 0.2], [-0.1, 0.1]])\n",
        "y = np.array([1, 0])\n",
        "w_init = np.zeros(X.shape[1])\n",
        "b_init = 0.0\n",
        "alpha = 0.1\n",
        "n_iter = 100\n",
        "\n",
        "w_out, b_out, cost_history, params_history = gradient_descent(X, y, w_init, b_init, alpha, n_iter, show_cost=False, show_params=False)\n",
        "\n",
        "print(\"\\nFinal parameters:\")\n",
        "print(f\"w: {w_out}, b: {b_out}\")\n",
        "print(f\"Final cost: {cost_history[-1]:.6f}\")\n",
        "\n",
        "# Simple assertion checks (as in worksheet)\n",
        "def test_gradient_descent():\n",
        "    assert len(cost_history) == n_iter, \"Cost history length does not match the number of iterations\"\n",
        "    assert w_out.shape == w_init.shape, \"Shape of output weights does not match the initial weights\"\n",
        "    assert isinstance(b_out, float), \"Bias output is not a float\"\n",
        "    assert cost_history[-1] < cost_history[0], \"Cost did not decrease over iterations\"\n",
        "    print(\"All tests passed for gradient_descent!\")\n",
        "\n",
        "test_gradient_descent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u4wxVL25uUL",
        "outputId": "220b85ff-1308-4c1e-f208-311fd96e9087"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final parameters:\n",
            "w: [0.49236201 0.24271295], b: -0.023120387837231953\n",
            "Final cost: 0.662954\n",
            "All tests passed for gradient_descent!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Decision / Prediction Function"
      ],
      "metadata": {
        "id": "C_ka5cny53pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def prediction(X, w, b, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Predicts binary outcomes for given input features based on logistic regression parameters.\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "    X (ndarray, shape (n,d)): Array of test independent variables (features) with n samples and d features.\n",
        "\n",
        "    w (ndarray, shape (d,)): Array of weights learned via gradient descent.\n",
        "\n",
        "    b (float): Bias learned via gradient descent.\n",
        "\n",
        "    threshold (float, optional): Classification threshold for predicting class labels. Default is 0.5.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    y_pred (ndarray, shape (n,)): Array of predicted dependent variable (binary class labels: 0 or 1).\n",
        "\n",
        "    \"\"\"\n",
        "    # Compute the predicted probabilities using the logistic function\n",
        "    y_test_prob = logistic_function(np.asarray(X).dot(w) + b)\n",
        "\n",
        "    # Classify based on the threshold\n",
        "    y_pred = (y_test_prob >= threshold).astype(int)\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "# Test for prediction (as in worksheet)\n",
        "def test_prediction():\n",
        "    X_test = np.array([[0.5, 1.0], [1.5, -0.5], [-0.5, -1.0]])\n",
        "    w_test = np.array([1.0, -1.0])\n",
        "    b_test = 0.0\n",
        "    threshold = 0.5\n",
        "    expected_output = np.array([0, 1, 1])\n",
        "    y_pred = prediction(X_test, w_test, b_test, threshold)\n",
        "    assert np.array_equal(y_pred, expected_output), f\"Expected {expected_output}, but got {y_pred}\"\n",
        "    print(\"Test passed for prediction!\")\n",
        "\n",
        "test_prediction()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkOdTGcS6QB-",
        "outputId": "e4771879-c046-4b5f-891f-533c6861121f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed for prediction!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Evaluating Classifier"
      ],
      "metadata": {
        "id": "RKh-guP26Xak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_classification(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes the confusion matrix, precision, recall, and F1-score for binary classification.\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "    y_true (ndarray, shape (n,)): Ground truth binary labels (0 or 1).\n",
        "\n",
        "    y_pred (ndarray, shape (n,)): Predicted binary labels (0 or 1).\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    metrics (dict): A dictionary containing confusion matrix, precision, recall, and F1-score.\n",
        "\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_pred = np.asarray(y_pred).astype(int)\n",
        "\n",
        "    TP = int(np.sum((y_true == 1) & (y_pred == 1)))  # True Positives\n",
        "    TN = int(np.sum((y_true == 0) & (y_pred == 0)))  # True Negatives\n",
        "    FP = int(np.sum((y_true == 0) & (y_pred == 1)))  # False Positives\n",
        "    FN = int(np.sum((y_true == 1) & (y_pred == 0)))  # False Negatives\n",
        "\n",
        "    # Confusion matrix\n",
        "    confusion_matrix = np.array([[TN, FP],\n",
        "                                 [FN, TP]])\n",
        "\n",
        "    # Precision, recall, and F1-score\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0.0 else 0.0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0.0 else 0.0\n",
        "    if precision + recall == 0:\n",
        "        f1_score = 0.0\n",
        "    else:\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    metrics = {\n",
        "        \"confusion_matrix\": confusion_matrix,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score,\n",
        "        \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# Quick test for evaluate_classification\n",
        "y_true = np.array([1, 0, 1, 0, 1])\n",
        "y_pred = np.array([1, 0, 0, 0, 1])\n",
        "metrics = evaluate_classification(y_true, y_pred)\n",
        "print(\"Confusion matrix:\\n\", metrics[\"confusion_matrix\"])\n",
        "print(f\"Precision: {metrics['precision']}, Recall: {metrics['recall']}, F1: {metrics['f1_score']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKO82MIy6ZG6",
        "outputId": "7a6169d3-0e3a-498e-c493-59b967099bad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[2 0]\n",
            " [1 2]]\n",
            "Precision: 1.0, Recall: 0.6666666666666666, F1: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Putting Helper Function to Action - Sigmoid Regression for the dataset:\n",
        "\n",
        "1. Some Basic Data Operation, Loading, Analysis and Cleaning:"
      ],
      "metadata": {
        "id": "CrnNNkui64iG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "columns = [\n",
        "    'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
        "    'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'\n",
        "]\n",
        "\n",
        "df = pd.read_csv(url, names=columns)\n",
        "\n",
        "# Display first few rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cNWHlCWy67Mk",
        "outputId": "5dfc2bd8-7925-4d9f-f4aa-862dbf7e6c2c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be1dd46c-6e14-4cca-b96b-8e03c1dd7ea0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be1dd46c-6e14-4cca-b96b-8e03c1dd7ea0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be1dd46c-6e14-4cca-b96b-8e03c1dd7ea0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be1dd46c-6e14-4cca-b96b-8e03c1dd7ea0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1b7e65fb-d634-429a-96a3-81b28687aee0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b7e65fb-d634-429a-96a3-81b28687aee0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1b7e65fb-d634-429a-96a3-81b28687aee0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.8841603203754405,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33132859501277484,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.2 Handling Missing or Invalid Values"
      ],
      "metadata": {
        "id": "KzxaIo_s7rKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns where zero is an invalid value\n",
        "cols_with_zero_invalid = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "\n",
        "# Replace zeros with NaN\n",
        "df[cols_with_zero_invalid] = df[cols_with_zero_invalid].replace(0, np.nan)\n",
        "\n",
        "# Fill NaN values with column median\n",
        "df.fillna(df.median(), inplace=True)\n",
        "\n",
        "# Verify no missing values remain\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "_YgEIO6C7t5t",
        "outputId": "288444bc-d7ae-4fa5-9a0f-f4470a0d4886"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pregnancies</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glucose</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BloodPressure</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SkinThickness</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Insulin</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BMI</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outcome</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.3 Splitting Features and Target Variable"
      ],
      "metadata": {
        "id": "lLrO9EJ57zjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['Outcome']).values\n",
        "y = df['Outcome'].values\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XytKRZWv7zwN",
        "outputId": "14772a2b-eef0-45f2-c4a9-3946f9d6e7b4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (768, 8)\n",
            "Shape of y: (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.4 TrainTest Split"
      ],
      "metadata": {
        "id": "qy-FJFUe8fmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Test set size:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xknn9qK78gWd",
        "outputId": "b75de352-5c43-46d3-cbf0-e2ba0542895a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (614, 8)\n",
            "Test set size: (154, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.5 Feature Scaling"
      ],
      "metadata": {
        "id": "VKToGiDH8lzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "a02kEKI08mhB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.6 Initializing Model Parameters"
      ],
      "metadata": {
        "id": "GCphFgG38q5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = X_train_scaled.shape[1]\n",
        "\n",
        "w_init = np.zeros(n_features)\n",
        "b_init = 0.0\n",
        "\n",
        "alpha = 0.1\n",
        "n_iter = 1000"
      ],
      "metadata": {
        "id": "uwUbsSlL8rww"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.7 Training Sigmoid Regression Model"
      ],
      "metadata": {
        "id": "H7xw5ZwS8vNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w_opt, b_opt, cost_history, params_history = gradient_descent(\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    w_init,\n",
        "    b_init,\n",
        "    alpha,\n",
        "    n_iter,\n",
        "    show_cost=True,\n",
        "    show_params=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4pS3y3882QZ",
        "outputId": "321db769-c539-4f15-e02f-6f476561d12a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Cost = 0.676575\n",
            "Iteration 100: Cost = 0.465441\n",
            "Iteration 200: Cost = 0.455913\n",
            "Iteration 300: Cost = 0.453874\n",
            "Iteration 400: Cost = 0.453316\n",
            "Iteration 500: Cost = 0.453148\n",
            "Iteration 600: Cost = 0.453096\n",
            "Iteration 700: Cost = 0.453079\n",
            "Iteration 800: Cost = 0.453074\n",
            "Iteration 900: Cost = 0.453072\n",
            "Iteration 999: Cost = 0.453071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.8 Visualizing Cost Reduction"
      ],
      "metadata": {
        "id": "aFpjve088_05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(cost_history)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.title(\"Cost Reduction During Training\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "2tBVpfiV89fD",
        "outputId": "f1427043-a0b1-406c-a48c-9396706f9869"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.9 Making Predictions on Test Data"
      ],
      "metadata": {
        "id": "a-I8Ux0c9RO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = prediction(X_test_scaled, w_opt, b_opt)"
      ],
      "metadata": {
        "id": "fA64ntws9Ra3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.10 Evaluating Model Performance"
      ],
      "metadata": {
        "id": "jO7mi_4f9Wyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = evaluate_classification(y_test, y_test_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(metrics[\"confusion_matrix\"])\n",
        "\n",
        "print(\"\\nPrecision:\", metrics[\"precision\"])\n",
        "print(\"Recall:\", metrics[\"recall\"])\n",
        "print(\"F1 Score:\", metrics[\"f1_score\"])\n",
        "\n",
        "accuracy = (y_test_pred == y_test).mean()\n",
        "print(\"\\nAccuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-wHAaA59XBz",
        "outputId": "ea60e76c-8302-4089-de01-343c6c07450c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[82 18]\n",
            " [27 27]]\n",
            "\n",
            "Precision: 0.6\n",
            "Recall: 0.5\n",
            "F1 Score: 0.5454545454545454\n",
            "\n",
            "Accuracy: 0.7077922077922078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.11 Inspecting Learned Parameters"
      ],
      "metadata": {
        "id": "l3kzAApC9X5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Bias (b):\", b_opt)\n",
        "\n",
        "print(\"\\nWeights:\")\n",
        "for feature_name, weight in zip(columns[:-1], w_opt):\n",
        "    print(f\"{feature_name}: {weight:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0RJLCbf9YG1",
        "outputId": "5c23ccc3-b8d7-44b2-d593-ac99252bfca0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bias (b): -0.876699116663487\n",
            "\n",
            "Weights:\n",
            "Pregnancies: 0.3850\n",
            "Glucose: 1.2054\n",
            "BloodPressure: -0.0499\n",
            "SkinThickness: 0.0227\n",
            "Insulin: -0.0753\n",
            "BMI: 0.7039\n",
            "DiabetesPedigreeFunction: 0.2365\n",
            "Age: 0.1467\n"
          ]
        }
      ]
    }
  ]
}